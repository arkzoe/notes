# 分布式缓存
单节点问题：数据丢失、并发能力、故障恢复、存储能力
## Redis持久化
### RDB
- RDB全称`Redis Database Backup file`（Redis数据备份文件），也被叫做Redis数据快照。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据
- 快照文件称为RDB文件，默认保存在当前运行目录
	- 子进程执行bgsave，避免主进程收到影响
- 服务停机时自动执行
- 具体配置在redis.conf中找到
- `save x y`
	- 在x秒内有y个key被修改执行bgsave
	- save “”：禁用RDB
- bgsave开始时fork主进程得到子进程此时阻塞，fork完写入
- fork采用`copy-on-write`技术
	- 主进程执行读操作，访问共享内存
	- 写操作，拷贝一份数据执行写操作
![[Pasted image 20260208193810.png]]
- 缺点
	- 执行间隔时间长，RDB之间写入有丢失风险
	- fork子进程、压缩、写入RDB文件耗时
### AOF持久化
AOF全称为`Append Only File`（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件
```sh
#是否开启AOF功能，默认是no
appendonly yes
#AOF文件的名称
appendfilename "appendonly.aof"

#AOF的命令记录的频率也可以通过redis.conf文件来配：
#表示每执行一次写命令，立即记录到AOF文件，性能最差
appendfsync always
#写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是默认方案
appendfsync everysec
#写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘
appendfsync no
```
因为是记录命令，AOF文件会比RDB文件大的多。而且AOF会记录对同一个key的多次写操作，但只有最后一次写操作才有意义。通过执行`bgrewriteaof`命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果
```sh
# AOF文件比上次文件 增长超过多少百分比则触发重写
auto-aof-rewrite-percentage 100
# AOF文件体积最小多大以上才触发重写
auto-aof-rewrite-min-size 64mb
```

|                |                     RDB                      |                            AOF                             |
| -------------- |:--------------------------------------------:|:----------------------------------------------------------:|
| 持久化方式     |             定时对整个内存做快照             |                    记录每一次执行的命令                    |
| 数据完整性     |          不完整，两次备份之间会丢失          |                  相对完整，取决于刷盘策略                  |
| 文件大小       |             会有压缩，文件体积小             |                   记录命令，文件体积很大                   |
| 岩机恢复速度   |                     很快                     |                             慢                             |
| 数据恢复优先级 |          低，因为数据完整性不如AOF           |                   高，因为数据完整性更高                   |
| 系统资源占用   |            高，大量CPU和内存消耗             | 低，主要是磁盘I0资源<br>但AOF重写时会占用大量CPU和内存资源 |
| 使用场景       | 可以容忍数分钟的数据丢失，追求更快的启动速度 |                  对数据安全性要求较高常见                  |
## 主从
### 主从架构
单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离
- 从节点slave/replica
### 同步原理
![[Pasted image 20260209193017.png]]
- `Replication Id`：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid,slave则会继承master节点的replid
- `offset`：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新
- 因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据
![[Pasted image 20260209193853.png]]
#### 优化
- 在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘lO
- Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO
- 适当提高repl_baklog的大小，发现slave岩机时尽快实现故障恢复，尽可能避免全量同步
- 限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力
## 哨兵
- `监控`：Sentinel会不断检查您的master和slave是否按预期工作
- `自动故障恢复`：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主
- `通知`：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端

Sentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令：
- `主观下线`：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例主观下线。
- `客观下线`：若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例客观下线。quorum值最好超过Sentinel实例数量的一半。

一旦发现master故障，sentinel需要在salve中选择一个作为新的master，选择依据是这样的:
- 首先会判断slave节点与master节点断开时间长短，如果超过指定值`down-after-milliseconds*10`则会排除该slave节点
- 然后判断slave节点的`slave-priority`值，越小优先级越高，如果是0则永不参与选举
- 如果slave-prority一样，则判断slave节点的`offset`值，越大说明数据越新，优先级越高
- 最后是判断slave节点的`运行id`大小，越小优先级越高

当选中了其中一个slave为新的master后（例如slave1），故障的转移
1. sentinel给备选的slave1节点发送`slave of no one`命令，让该节点成为master
2. sentinel给所有其它slave发送`slave of 192.168.150.101 7002`命令，让这些slave成为新master的从节点，开始从新的master上同步数据。
3. 最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点
### RedisTemplate哨兵模式
- 配置文件中指定sential相关信息
- 配置主从读写分离
```java
@Bean
public LettuceClientConfigurationBuilderCustomizer configurationBuilderCustomizer(){
	return configBuilder -> configBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);
}
```
这里的ReadFrom是配置Redis的读取策略，是一个枚举，包括下面选择：
- `MASTER`：从主节点读取
- `MASTER_PREFERRED`： 优先从master节点读取，master不可用才读取replica
- `REPLICA`：从slave（replica）节点读取
- `REPLICA_PREFERRED`：优先从slave（replica）节点读取，所有的slave都不可用才读取master
## 分片集群
主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决
- 海量数据存储问题
- 高并发写的问题

使用分片集群可以解决上述问题，分片集群特征：
- 集群中有多个master，每个master保存不同数据
- 每个master都可以有多个slave节点
- master之间通过ping监测彼此健康状态
- 客户端请求可以访问集群任意节点，最终都会被转发到正确节点
### 散列插槽
Redis会把每一个master节点映射到0~16383共16384个插槽（hashslot）上，查看集群信息时就能看到

数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值，分两种情况：
- key中包含"{}"，且“{}"中至少包含1个字符，“{}”中的部分是有效部分
- key中不包含“{}”，整个key都是有效部分
例如：key是num，那么就根据num计算，如果是{itcast}num，则根据itcast计算。计算方式是利用cRC16算法得到一个hash值，然后对16384取余，得到的结果就是slot值。
### 集群伸缩
redis-cli--cluster提供了很多操作集群的命令
添加删除节点需手动插槽分配
### 故障转移
1. 实例与其他实例失去连接
2. 疑似宕机
3. 确定下线，自动提升一个slave为新的master
#### 手动故障转移
利用cluster failover命令可以手动让集群中的某个master宕机，切换到执行clusterfailover命令的这个slave节点，实现无感知的数据迁移。其流程
![[Pasted image 20260209205740.png]]
手动的Failover支持三种不同模式：
- `缺省`：默认的流程，如图1~6步
- `force`：省略了对offset的一致性校验
- `takeover`：直接执行第5步，忽略数据一致性、忽略master状态和其它master的意见
### RedisTemplate访问分片集群
1. 引l入redis的starter依赖
2. 配置分片集群地址
3. 配置读写分离
# 多级缓存
传统缓存策略是请求到达Tomcat，先查询Redis，未命中查询数据库
- 请求通过Tomcat处理，tomcat成为性能瓶颈
- Redis缓存失效，对数据库

多级缓存充分利用请求处理的每个环节，分别添加缓存，减轻Tomcat压力，提升服务质量
![[Pasted image 20260210134641.png]]
## JVM进程缓存
- 分布式缓存，例如Redis:
	- 优点：存储容量更大、可靠性更好、可以在集群间共享
	- 缺点：访问缓存有网络开销
	- 场景：缓存数据量较大、可靠性要求较高、需要在集群间共享
- 进程本地缓存，例如HashMap、GuavaCache:
	- 优点：读取本地内存，没有网络开销，速度更快
	- 缺点：存储容量有限、可靠性较低、无法共享
	- 场景：性能要求较高，缓存数据量较小
### Caffeine
Caffeine是一个基于java8开发的，提供了近乎最佳命中率的高性能的本地缓存库。目前Spring内部的缓存使用的就是Caffeine。 GitHub地址: https://github.com/ben-manes/caffeine
```JAVA
@Test
void testBasicOps() {
	//创建缓存对象
	Cache<String, String> cache = Caffeine.newBuilder().build();
	//存数据
	cache.put("gf"，"迪丽热巴");
	//取数据，不存在则返回null
	String gf = cache.getIfPresent("gf");System.out.println("gf = " + gf);
	
	//取数据，不存在则去数据库查询
	String defaultGF = cache.get("defaultGF", key -> {
		//这里可以去数据库根据key查询value
		return "柳岩"；
	});
	System.out.println("defaultGF = " + defaultGF);
}
```
- 基于容量：设置缓存的数量上限
```java
//创建缓存对象
Cache<String, String> cache = Caffeine.newBuilder()
	.maximumSize（1）// 设置缓存大小上限为
	.build();
```
- 基于时间：设置缓存的有效时间
```java
//创建缓存对象
Cache<String, String> cache = Caffeine.newBuilder()
.expireAfterWrite(Duraion.ofSeconds(10)）// 设置缓存有效期为 10 秒，从最后一次写入开始计时
.build();
```
- 基于引用：设置缓存为软引用或弱引用，利用GC回收缓存数据。性能较差，不建议使用
在默认情况下，当一个缓存元素过期的时候，Caffeine不会自动立即将其清理和驱逐。而是在一次读或写操作后，或者在空闲时间完成对失效数据的驱逐
### Lua
Lua是一种轻量小巧的脚本语言，用标准c语言编写并以源代码形式开放，其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。官网：https://www.lua.org/

| 数据类型     | 描述                                                                                                                |
| -------- | ----------------------------------------------------------------------------------------------------------------- |
| nil      | 这个最简单，只有值ni礼属于该类，表示一个无效值（在条件表达式中相当于false）                                                                         |
| boolean  | 包含两个值：false和true                                                                                                  |
| number   | 表示双精度类型的实浮点数                                                                                                      |
| string   | 字符串由一对双引号或单引号来表示                                                                                                  |
| function | 由C 或 Lua 编写的函数                                                                                                    |
| table    | Lua 中的表（table）其实是一个"关联数组"（associativearrays），数组的索引可以是数字、字符串或表类型。在Lua 里，table的创建是通过"构造表达式"来完成，最简单构造表达式是{}，用来创建一个空表 |
#### 变量
```lua
--声明字符串
local str = 'hello'
--声明数字
local num = 21
--声明布尔类型
local flag = true
--声明数组 key为索引的 table
local arr = {'java', 'python', 'lua'}
--声明table，类似java的map
local map = {name='Jack', age=21}

.. 拼接字符串
```
#### 字符串
遍历数组：
```lua
--声明数组 key为索引的 table
local arr = {'java', 'python', 'lua'}
--遍历数组
for index,value in ipairs(arr) do\
	print(index, value)
end
```
遍历table:
```lua
--声明map，也就是table
local map = {name='Jack', age=21}
--遍历table
for key,value in pairs(map) do
	print(key, value)
end
```
#### 函数
定义函数语法：
```lua
function 函数名( argument1， argument2...， argumentn)
	--函数体
	return 返回值
end
```
#### 条件控制
类似Java的条件控制，例如if、else语法:.
```lua
if(布尔表达式)
then
--［ 布尔表达式为 true 时执行该语句块 --]
else
--［ 布尔表达式为 false 时执行该语句块 --］
end
```
布尔表达式

| 操作符 | 描述                                     | 实例                 |
| --- | -------------------------------------- | ------------------ |
| and | 逻辑与操作符。若 A 为 false，则返回 A，否则返回B         | (A and B) 为 false  |
| or  | 逻辑或操作符。若 A 为 true，则返回 A，否则返回 B         | (A or B) 为 true    |
| not | 逻辑非操作符。与逻辑运算结果相反，如果条件为 true，逻辑非为 false | not(A and B)为 true |
## OpenResty
OpenResty?是一个基于Nginx的高性能Web平台，用于方便地搭建能够处理超高并发、扩展性极高的动态Web应用、Web 服务和动态网关。具备下列特点：
- 具备Nginx的完整功能
- 基于Lua语言进行扩展，集成了大量精良的Lua库、第三方模块
- 允许使用Lua自定义业务逻辑、自定义库

1. 在nginx.conf的http下面，添加对OpenResty的Lua模块的加载:
```nginx
#加载lua 模块
lua_package_path "/usr/local/openresty/lualib/?.lua;;";
#加载c模块
lua_package_cpath "/usr/local/openresty/lualib/?.so;;";
```
2. 在nginx.conf的server下面，添加对/api/item这个路径的监听:
```nginx
location /api/item {
	#响应类型，这里返回json
	default_type application/json;
	#响应数据由 lua/item。lua这个文件来决定
	content_by_lua_file lua/item.lua;
}
```

| 参数格式     | 参数示例         |                                                                                                                                               |
| -------- | ------------ | --------------------------------------------------------------------------------------------------------------------------------------------- |
| 路径占位符    | /item/1001   | #1.正则表达式匹配：<br>location ~/item/(\d+) {<br>    content_by_lua_file lua/item.lua;<br>}<br>--匹配到的参数会存入ngx.vak数组中可以用角标获取<br>local id = ngx.var[1] |
| 请求头      | id: 1001     | --获取请求头，返回值是table类型<br>local headers = ngx.req.get_headers()                                                                                  |
| Get请求参数  | ?id=1001     | --获取GET请求参数，返回值是table类型<br>local getParams = ngx.req.get_uri_args()                                                                           |
| Post表单参数 | id=1001      | --读取请求体<br>ngx.req.read_body()<br>--获取POST表单参数，返回值是table类型<br>local postParams = ngx.req.get_post_args()                                      |
| JSON参数   | {"id": 1001} | --读取请求体<br>ngx.req.read_body()<br>--获取body中的json参数，返回值是string类型<br>local jsonBody = ngx.req.get_body_data()                                   |
#### 封装http请求
nginx提供了内部APi用以发送htp请求：
```nginx
local resp = ngx.location.capture("/path",{
	method = ngx.HTTP_GET, -- 请求方式
	args ={a=1,b=2}, -- get方式传参数
	body = "c=3&d=4" -- post方式传参数
})
```
返回的响应内容包括：
- resp.status：响应状态码
- resp.header:响应头，是一个table
- resp.body：响应体，就是响应数据

注意：这里的path是路径，并不包含IP和端口。这个请求会被nginx内部的server监听并处理。
但是我们希望这个请求发送到Tomcat服务器，所以还需要编写一个server来对这个路径做反向代理：
```nginx
location /path {
	#这里是windows电脑的ip和Java服务端口，需要确保windows防火墙处于关闭状态
	proxy_pass http://192.168.150.1:8081;
}
```

我们可以把http查询的请求封装为一个函数，放到OpenResty函数库中，方便后期使用。
1. 在/usr/local/openresty/lualib目录下创建common.lua文件:
```shell
vi /usr/local/openresty/lualib/common.lua
```
2. 在common.lua中封装http查询的函数
```lua
--封装函数，发送http请求，并解析响应
local function read_http(path, params)
	local resp = ngx.location.capture(path,{
		method = ngx.HTTP_GET,
		args = params;
	})
	if not resp then
		--记录错误信息，返回404
		ngx.log(ngx.ERR, "http not found, path: ", path ,", args: ", args)
		ngx.exit(404)
	end
	return resp.body
end
--将方法导出
local _M = {
	read_http = read_http
}
return _M
```
#### JSON
OpenResty提供了一个cjson的模块用来处理JSON的序列化和反序列化
官方地址: https://github.com/openresty/lua-cjson/
```nginx
# 引入cjson模块：
local cjson = require "cjson"
# 序列化：
local obj = {
	name = 'jack',
	age = 21
}
local json = cjson.encode(obj)
# 反序列化：
local json = '{"name": "jack", "age": 21}'
# 反序列化
local obj = cjson.decode(json);
print(obj.name)
```
#### Tomcat集群均衡负载
![[Pasted image 20260212134533.png]]
#### 添加redis缓存
![[Pasted image 20260212134451.png]]
##### 冷启动与缓存预热
**冷启动**：服务刚刚启动时，Redis中并没有缓存，如果所有商品数据都在第一次查询时添加缓存，可能会给数据库带来较大压力
**缓存预热**：在实际开发中，我们可以利用大数据统计用户访问的热点数据，在项目启动时将这些热点数据提前查询并保存到Redis中
#### OpenResty的Redis模块
引l入Redis模块，并初始化Redis对象
```lua
--引入redis模块
local redis = require("resty.redis")－ 初始化Redis对象
local red = redis:new()设置Redis超时时间
red:set_timeouts(1000, 1000, 1000)
```
封装函数，用来释放Redis连接，其实是放入连接池
```lua
--关闭redis连接的工具方法，其实是放入连接池
local function close_redis(red)
	local pool_max_idle_time = 10000 -- 连接的空闲时间，单位是毫秒
	local pool_size = 100 --连接池大小
	local ok, err = red:set_keepalive(pool_max_idle_time, pool_size)
	if not ok then
		ngx.log(ngx.ERR，"放入Redis连接池失败："，err)
	end
end
```
封装函数，从Redis读数据并返回
```lua
-- 查询redis的方法 ip和port是redis地址，key是查询的key
local function Kead_redis(ip, port, key)
	-- 获取一个连接
	local ok, err = red:connect(ip, port)
	if not ok then
		ngx.log(ngx.ERR，"连接redis失败："，err)
		return nil
	end
	--查询redis
	local resp, err = red:get(key)
	--查询失败处理
	if not resp then
		ngx.log(ngx.ERR，"查询Redis失败:"，err，"，key ="，key)
	end
	--得到的数据为空处理
		if resp == ngx.null then
		resp = nil
		ngx.log(ngx.ERR，"查询Redis数据为空，key = "，key)
	end
		close_redis(red)
	return resp
end
```
#### nginx本地缓存
OpenResty为Nginx提供了shard dict的功能，可以在nginx的多个worker之间共享数据，实现缓存功能开启共享字典，在nginx.conf的http下添加配置：
```nginx
#共享字典，也就是本地缓存，名称叫做：item_cache，大小150
mlua_shared_dict item_cache 150m;
```
操作共享字典：
```lua
--获取本地缓存对象
local item_cache = ngx.shared.item_cache
--存储，指定key、value、过期时间，单位s，默认为o代表永不过期
item_cache:set('key', 'value', 1000)
--读取
local val = item_cache:get('key')
```
## 缓存同步
缓存数据同步的常见方式有三种：
- `设置有效期`：给缓存设置有效期，到期后自动删除。再次查询时更新
	- 优势：简单、方便
	- 缺点：时效性差，缓存过期之前可能不一致
	- 场景：更新频率较低，时效性要求低的业务
- `同步双写`：在修改数据库的同时，直接修改缓存
	- 优势：时效性强，缓存与数据库强一致
	- 缺点：有代码侵入，耦合度高；
	- 场景：对一致性、时效性要求较高的缓存数据
- `异步通知`：修改数据库时发送事件通知，相关服务监听到通知后修改缓存数据
	- 优势：低耦合，可以同时通知多个缓存服务
	- 缺点：时效性一般，可能存在中间不一致状态
	- 场景：时效性要求一般，有多个服务需要同步
![[Pasted image 20260212160103.png]]![[Pasted image 20260212160151.png]]
### Canal
Canal，译意为水道/管道/沟渠，canal是阿里巴巴旗下的一款开源项目，基于Java开发。基于数据库增量日志解析，提供增量数据订阅&消费。GitHub的地址：https://github.com/alibaba/canal

Canal是基于mysql的主从同步来实现的，MySQL主从同步的原理
- MySQL master 将数据变更写入二进制日志(binary log），其中记录的数据叫做binary log events
- MySQL slave 将 master 的 binary log events拷贝到它的中继日志(relay log)
- MySQL slave 重放relay log 中事件，将数据变更反映它自己的数据

Canal提供了各种语言的客户端，当Canal监听到binlog变化时，会通知Canal的客户端。不过这里我们会使用GitHub上的第三方开源的canal-starter。 地址： https://github.com/NormanGyllenhaal/canal-client
引入依赖：
```java
<!--canal-->
<dependency>
	<groupId>top.javatool</groupId>
	<artifactId>canal-spring-boot-starter</artifactId>
	<version>1.2. 1-RELEASE</version>
</dependency>
```
编写配置：
```java
canal:
destination： heima # canal实例名称，要跟canal-server运行时设置的destination一致
server: 192.168.150.101:11111 # canal地址
```
```JAVA
package com.heima.item.canal;
@CanalTable("tb_item")//监听表
@Component
public class ItemHandler implements EntryHandler<Item> {//关联实体类
//数据库增删改
	@override
	public void insert(Item item) {
	//新增数据到redis
	}
	@Override
	public void update(Item before, Item after) {
	// 更新redis数据
	//更新本地缓存
	}
	@0verride
	public void delete(Item item) {
	//删除redis数据
	//清理本地缓存
	}
}
```

Canal推送给canal-client的是被修改的这一行数据（row），而我们引l入的canal-client则会帮我们把行数据封装到Item实体类中。这个过程中需要知道数据库与实体的映射关系，要用到JPA的几个注解：
```java
@Data
@TableName("tb_item")
public class Item {
	@TableId(type = IdType.AUTo)
	@Id//标记表中的id字段
	private Long id;
	@Column (name="name")//标记表中与属性名不一致的字段
	private String name;
	//··．其它字段略
	private Date updateTime;
	@TableField(exist = false)
	@Transient//标记不属于表中的字段
	private Integer stock;
	@TableField(exist= false)
	@Transient
	private Integer sold;
}
```
# Redis最佳实践
## Redis键值设计
### 优雅key
Redis的Key虽然可以自定义，但最好遵循下面的几个最佳实践约定：
	- 遵循基本格式：`[业务名称]:[数据名]:[id]`
	- 长度不超过44字节
	- 不包含特殊字符
优：
	- 可读性强
	- 避免key冲突
	- 方便管理
	- 更节省内存：key是string类型，底层编码包含int、embstr和raw三种。embstr在小于44字节使用，采用连续内存空间，内存占用更小
### 拒绝BigKey
- BigKey通常以Key的大小和Key中成员的数量来综合判定，例如：
	- Key本身的数据量过大：一个String类型的Key，它的值为5 MB。
	- Key中的成员数过多：一个ZSET类型的Key，它的成员数量为10,000个。
	- Key中成员的数据量过大：一个Hash类型的Key，它的成员数量虽然只有1,000个但这些成员的Value（值）总大小为100 MB。
- 推荐值：
	- 单个key的value小于10KB
	- 对于集合类型的key，建议元素数量小于1000
#### 危害
- 网络阻塞
	- 对BigKey执行读请求时，少量的QPS就可能导致带宽使用率被占满，导致Redis实例，乃至所在物理机变慢
- 数据倾斜
	- BigKey所在的Redis实例内存使用率远超其他实例，无法使数据分片的内存资源达到均衡
- Redis阻塞
	- 对元素较多的hash、list、Zset等做运算会耗时较l旧，使主线程被阻塞
- CPU压力
	- 对BigKey的数据序列化和反序列化会导致CPU的使用率飙升，影响Redis实例和本机其它应用
#### 发现BigKey
- `redis-cli --bigkeys`
	- 利用redis-cli提供的--bigkeys参数，可以遍历分析所有key，并返回Key的整体统计信息与每个数据的Top1的big key
- `scan扫描`
	- 自己编程，利用scan扫描Redis中的所有key，利用strlen、hlen等命令判断key的长度（此处不建议使用MEMORY USAGE）
```java
final static int STR_MAX_LEN = 10 * 1024;
final static int HASH_MAX_LEN = 5o;
@Test
void testScan() {
	int maxLen = 0;
	long len = 0;
	String cursor = "0";
	do {
		//扫描并获取一部分key
		ScanResult<String> result = jedis.scan(cursor) ;
		//  记录cursor
		cursor = result.getcursor();
		List<String> list = result.getResult();
		if (list == null Il list.isEmpty()) {
		break;
		}
		//遍历
		for (String key : list) {
			//判断key的类型
			String type = jedis.type(key) ;
			switch(type){
				case "string"
					len = jedis.strlen(key) ;
					maxLen = STR_MAX_LEN;
					break;
				case "hash":
					len = jedis.hlen(key) ;
					maxLen = HASH_MAX_LEN;
					break;
				case "list":
					len = jedis.llen(key);
					maxLen = HASH_MAX_LEN;
					break;
				case "set!:
					len = jedis.scard(key) ;
					maxLen = HASH_MAX_LEN;
					break;
				case "zset":
					len = jedis.zcard(key);
					maxLen = HASH_MAX_LEN;
					break;
				default:
					break;
			}
			if(len >= maxLen){
				System.out.printf("Found big key : type: %s, Length or size: %d %n"
					,key,type,len);
			}
		}
	}while(!cursor.equals("0"));
}
```
- `第三方工具`
	- 利用第三方工具，如Redis-Rdb-Tools 分析RDB快照文件，全面分析内存使用情况
- `网络监控`
	- 自定义工具，监控进出Redis的网络数据，超出预警值时主动告警
#### 删除BigKey
BigKey内存占用较多，即便时删除这样的key也需要耗费很长时间，导致Redis主线程阻塞，引发一系列问题
- redis3.0及以下版本
	- 如果是集合类型，则遍历BigKey的元素，先逐个删除子元素，最后删除BigKey
- Redis 4.0以后
	- Redis在4.0后提供了异步删除的命令：unlink
### 恰当的数据类型
#### 例1：比如存储一个User对象，我们有三种存储方式：
1. json字符串

| user:1 | {"name": "Jack", "age": 21} |
| ------ | --------------------------- |
优点：实现简单粗暴
缺点：数据耦合，不够灵活

2. 字段打散

| user:1:name | Jack |
| ----------- | ---- |
| user:1:age  | 21   |
优点：可以灵活访问对象任意字段
缺点：占用空间大，无法统一控制

3. hash

| user:1 | name | Jack |
| ------ | ---- | ---- |
|        | jack | 21   |
优点：底层使用ziplist，空间占用小，可以灵活访问对象的任意字段
缺点：代码相对复杂
#### 假如有hash类型的key，其中有10o万对field和value，field是自增id，这个key存在什么问题？如何优化？

| KEY     | field      | value       |
| ------- | ---------- | ----------- |
|         | id:0       | value0      |
| somekey | ...        | ...         |
|         | id:9999999 | value999999 |
存在问题
1. hash的entry数量超过500时，会使用哈希表而不是ZipList，内存占用较多
2. 可以通过hash-max-ziplist-entries配置entry上限。但是如果entry过多就会导致BigKey问题
##### 方案
1. 拆成string类型

| key       | value       |
| --------- | ----------- |
| id:0      | value0      |
| ...       | ...         |
| id:999999 | value999999 |
存在的问题：
- string结构底层没有太多内存优化，内存占用较多
- 想要批量获取这些数据比较麻烦

2. 拆分为小的hash，将 id / 10θ 作为key， 将id % 10θ 作为field，这样每100个元素为一个Hash

| KEY   | field | value   |
| ----- | ----- | ------- |
|       | id:0  | value0  |
| key：0 | ...   | ...     |
|       | id:99 | value99 |
## 批处理优化
#### 单个命令执行流程
一次命令的响应时间=1次往返的网络传输耗时+1次Redis执行命令耗时
![[Pasted image 20260222121003.png]]
#### N个命令执行流程
N次命令的响应时间=N次往返的网络传输耗时+N次Redis执行命令耗时
#### N个命令批量执行
N次命令的响应时间=1次往返的网络传输耗时+N次Redis执行命令耗时
![[Pasted image 20260222121320.png]]
使用Mxx，批量插入数据
### Pipeline
MSET虽然可以批处理，但是却只能操作部分数据类型，因此如果有对复杂数据类型的批处理需要，建议使用Pipeline功能
```java
@Test
void testPipeline() {
	//创建管道
	Pipeline pipeline = jedis.pipelined();
	for （int i = 1; i <= 100000; i++） {
		//放入命令到管道
		pipeline.set("test:key_" + i, "value_" + i);
		if （i % 1000 == 0） {
		//每放入1000条命令，批量执行
		pipeline.sync() ;
		}
	}
}
```
批处理时不建议一次携带太多命令
Pipeline的多个命令之间不具备原子性
### 集群下的批处理
如MSET或Pipeline这样的批处理需要在一次请求中携带多条命令，而此时如果Redis是一个集群，那批处理命令的多个key必须落在一个插槽中，否则就会导致执行失败

|      | 串行命令                | 串行slot                                                           | 井行slot                                                          | hash_tag                               |
| ---- | ------------------- | ---------------------------------------------------------------- | --------------------------------------------------------------- | -------------------------------------- |
| 实现思路 | for循环遍历<br>依次执行每个命令 | 在客户端计算每个key的slot<br>将slot一致分为一组<br>每组都利用PipeLine批处理。<br>串行执行各组命令 | 在客户端计算每个key的slot<br>将slot一致分为一组<br>每组都利用Pipeline批处理<br>并行执行各组命令 | 将所有key设置相同的hash_tag<br>则所有key的slot一定相同 |
| 耗时   | N次网络耗时 + <br>N次命令耗时 | m次网络耗时+N次命令耗时<br>m = key的slot个数                                  | 1次网络耗时+<br>N次命令耗时                                               | 1次网络耗时<br>+N次命令耗时                      |
| 优点   | 实现简单                | 耗时较短                                                             | 耗时非常短                                                           | 耗时非常短、实现简单                             |
| 缺点   | 耗时非常久               | 实现稍复杂<br>slot越多，耗时越久                                             | 实现复杂                                                            | 容易出现数据倾斜                               |
## 服务端优化
### 持久化配置
Redis的持久化虽然可以保证数据安全，但也会带来很多额外的开销，因此持久化请遵循下列建议：
- 用来做缓存的Redis实例尽量不要开启持久化功能
- 建议关闭RDB持久化功能，使用AOF持久化
- 利用脚本定期在slaVe节点做RDB，实现数据备份
- 设置合理的rewrite阀值，避免频繁的bgrewrite
- 配置no-appendfsync-on-rewrite=yes，禁止在rewrite期间做aof，避免因AOF引起的阻塞
部署有关建议：
- Redis实例的物理机要预留足够内存，应对fork和rewrite
- 单个Redis实例内存上限不要太大，例如4G或8G。可以加快fork的速度、减少主从同步、数据迁移压力
- 不要与CPU密集型应用部署在一起
- 不要与高硬盘负载应用一起部署。例如：数据库、消息队列
### 慢查询
执行耗时超过某个阈值
慢查询的值可以通过配置指定：
- `slowlog-log-slower-than`：慢查询阈值，单位是微秒。默认是10000，建议1000
慢查询会被放入慢查询日志中，日志的长度有上限，可以通过配置指定：
- `slowlog-max-len`：慢查询日志（本质是一个队列）的长度。默认是128，建议1000
查看慢查询日志列表：
- `slowlog len`：查询慢查询日志长度
- `slowlog get [n]`: 读取n条慢查询日志
- `slowlogreset`:清空慢查询列表
### 命令及安全配置
Redis会绑定在0.0.0.0:6379，这样将会将Redis服务暴露到公网上，而Redis如果没有做身份认证，会出现严重的安全漏洞，漏洞重现方式：https://cloud.tencent.com/developer/article/1039000
出现原因
- Redis未设置密码
- 利用了Redis的config set命令动态修改Redis配置
- 使用了Root账号权限启动Redis
建议：
- Redis一定要设置密码
- 禁止线上使用下面命令：keys、flushall、flushdb、config set等命令。可以利用rename-command禁用
- bind：限制网卡，禁止外网网卡访问
- 开启防火墙
- 不要使用Root账户启动Redis
- 尽量不是有默认的端口
### 内存配置
当Redis内存不足时，可能导致Key频繁被删除、响应时间变长、QPS不稳定等问题。当内存使用率达到90%以上时就需要我们警惕，并快速定位到内存占用的原因

| 内存占用   | 说明                                                                                                                                                    |
| ---------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 数据内存   | 是Redis最主要的部分，存储Redis的键值信息。主要问题是BigKey问题、内存碎片问题                                                                            |
| 进程内存   | Redis主进程本身运行肯定需要占用内存，如代码、常量池等等；这部分内存大约几兆，在大多数生产环境中与Redis数据占用的内存相比可以忽略。                      |
| 缓冲区内存 | 一般包括客户端缓冲区、AOF缓冲区、复制缓冲区等。客户端缓冲区又包括输入缓冲区和输出缓冲区两种。这部分内存占用波动较大，不当使用BigKey，可能导致内存溢出。 |
- info memory
- memory xxx
#### 内存缓冲区配置
- `复制缓冲区`：主从复制的repl_backlog_buf，如果太小可能导致频繁的全量复制，影响性能。通过repl-backlog-size来设置，默认1mb
- `AOF缓冲区`：AOF刷盘之前的缓存区域，AOF执行rewrite的缓冲区。无法设置容量上限
- `客户端缓冲区`：分为输入缓冲区和输出缓冲区，输入缓冲区最大1G且不能设置。输出缓冲区可以设置
![[Pasted image 20260222185801.png]]
## 集群最佳实践
集群虽然具备高可用特性，能实现自动故障恢复，但是如果使用不当，也会存在一些问题：
- 集群完整性问题
	- 在Redis的默认配置中，如果发现任意一个插槽不可用，则整个集群都会停止对外服务
	- 为了保证高可用特性，这里建议将cluster-require-full-coverage配置为false
- 集群带宽问题
- 数据倾斜问题
- 客户端性能问题
- 命令的集群兼容性问题
- lua和事务问题
### 带宽问题
集群节点之间会不断的互相Ping来确定集群中其它节点的状态。每次Ping携带的信息至少包括：
- 插槽信息
- 集群状态信息
集群中节点越多，集群状态信息数据量也越大，10个节点的相关信息可能达到1kb，此时每次集群互通需要的带宽会非常高。
解决途径：
- 避免大集群，集群节点数不要太多，最好少于1000，如果业务庞大，则建立多个集群
- 避免在单个物理机中运行太多Redis实例
- 配置合适的cluster-node-timeout值
### 集群还是主从
集群虽然具备高可用特性，能实现自动故障恢复，但是如果使用不当，也会存在一些问题：
- 集群完整性问题
- 集群带宽问题
- 数据倾斜问题
- 客户端性能问题
- 命令的集群兼容性问题
- lua和事务问题
单体Redis（主从Redis）已经能达到万级别的QPS，并且也具备很强的高可用特性。如果主从能满足业务需求的情况下，尽量不搭建Redis集群。